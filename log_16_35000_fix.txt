------------ Options -------------
audio_sampling_rate: 11025
audio_window: 65535
batchSize: 8
beta1: 0.9
checkpoints_dir: checkpoints/
classifier_loss_weight: 0.05
classifier_pool: maxpool
continue_train: True
coseparation_loss_weight: 1.0
data_path: /your_data_root/MUSICDataset/solo/
decay_factor: 0.1
display_freq: 10
enable_data_augmentation: True
epoch_count: 0
gpu_ids: [1, 2]
hdf5_path: /home/manhnguyen/new/co-separation/dataset/sample_hdf5
log_freq: True
lr_classifier: 0.0001
lr_steps: [15000, 30000]
lr_unet: 0.0001
lr_visual: 1e-05
mask_loss_type: L1
mask_thresh: 0.5
measure_time: False
mode: train
model: audioVisualMUSIC
nThreads: 32
name: audioVisual
niter: 10
num_batch: 100000
num_object_per_video: 2
num_per_mix: 2
num_visualization_examples: 20
number_of_classes: 15
optimizer: adam
preserve_ratio: False
save_latest_freq: 500
scene_path: /your_root/hdf5/ADE.h5
seed: 0
stft_frame: 1022
stft_hop: 256
subtract_mean: True
tensorboard: True
unet_input_nc: 1
unet_ngf: 64
unet_num_layers: 7
unet_output_nc: 1
validation_batches: 20
validation_freq: 200
validation_on: True
validation_visualization: True
visual_pool: conv1x1
weight_decay: 0.0001
weighted_loss: True
weights_classifier: 
weights_unet: 
weights_visual: 
with_additional_scene_image: False
-------------- End ----------------
CustomDatasetDataLoader
dataset [AudioVisualMUSICDataset] was created
#training images = 800000
CustomDatasetDataLoader
dataset [AudioVisualMUSICDataset] was created
#validation images = 160
